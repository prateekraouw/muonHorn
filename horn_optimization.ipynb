{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f48c3b3",
   "metadata": {},
   "source": [
    "# GPU‑Optimized Horn Optimization for Compute Clusters\n",
    "\n",
    "This notebook is auto‑converted from your Python script.  \n",
    "**Structure rules honored:**\n",
    "- Each **function** is in its **own code cell**.\n",
    "- The **class** (with all member methods) is in its **own code cell**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2b3d8",
   "metadata": {},
   "source": [
    "**Original header:**\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "GPU-Optimized Horn Optimization for Compute Clusters\n",
    "- CUDA-accelerated data processing\n",
    "- Multi-GPU support for parallel Geant4 runs\n",
    "- Cluster-optimized resource management\n",
    "- SLURM/PBS job integration\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json, time, hashlib, subprocess, shutil\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda as cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PI_PLUS_MASS_MEV = 139.57039\n",
    "DEFAULT_ENERGY_WINDOW = (100.0, 400.0)\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f0dd",
   "metadata": {},
   "source": [
    "## GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd71eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Configuration\n",
    "def setup_gpu():\n",
    "    \"\"\"Setup GPU configuration for cluster computing.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        current_gpu = torch.cuda.current_device()\n",
    "        gpu_name = torch.cuda.get_device_name(current_gpu)\n",
    "\n",
    "        print(f\"🚀 GPU Setup:\")\n",
    "        print(f\"   Available GPUs: {gpu_count}\")\n",
    "        print(f\"   Current GPU: {current_gpu} ({gpu_name})\")\n",
    "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(current_gpu).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "        # Set memory allocation strategy\n",
    "        torch.cuda.empty_cache()\n",
    "        return device, gpu_count\n",
    "    else:\n",
    "        print(\"⚠️  No CUDA GPUs available, falling back to CPU\")\n",
    "        return torch.device(\"cpu\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GPU\n",
    "DEVICE, GPU_COUNT = setup_gpu()\n",
    "\n",
    "# Simple paths\n",
    "RUNS_ROOT = \"runs\"\n",
    "DATASET = \"dataset.csv\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(RUNS_ROOT, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Geant4 executable path\n",
    "GEANT4_EXE = os.environ.get(\"HORN_SIM_EXE\", \"/afs/hep.wisc.edu/user/pprao/muonHorn/build/horn_sim\")\n",
    "\n",
    "# Environment variables for Geant4\n",
    "EXTRA_ENV = {\n",
    "    \"LD_LIBRARY_PATH\": os.environ.get(\"LD_LIBRARY_PATH\", \"\"),\n",
    "    \"OMP_NUM_THREADS\": str(os.cpu_count()),\n",
    "    \"CUDA_VISIBLE_DEVICES\": os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"0\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04842d4",
   "metadata": {},
   "source": [
    "## HornParams dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class HornParams:\n",
    "    # geometry (shared by both horns)\n",
    "    a_mm: float\n",
    "    Rout_mm: float\n",
    "    r_neck_mm: float\n",
    "    zMin_mm: float\n",
    "    zMax_mm: float\n",
    "    r_max_mm: float\n",
    "    # current (Horn1:+I, Horn2:-I)\n",
    "    I_A: float\n",
    "    # placement\n",
    "    spacing_mm: float\n",
    "    # run control (not searched unless you want to)\n",
    "    n_events: int = 10000\n",
    "\n",
    "    def as_cli(self) -> List[str]:\n",
    "        return [\n",
    "            \"--a_mm\",        f\"{self.a_mm}\",\n",
    "            \"--r_neck_mm\",   f\"{self.r_neck_mm}\",\n",
    "            \"--Rout_mm\",     f\"{self.Rout_mm}\",\n",
    "            \"--zMin_mm\",     f\"{self.zMin_mm}\",\n",
    "            \"--zMax_mm\",     f\"{self.zMax_mm}\",\n",
    "            \"--r_max_mm\",    f\"{self.r_max_mm}\",\n",
    "            \"--I_A\",         f\"{self.I_A}\",\n",
    "            \"--spacing_mm\",  f\"{self.spacing_mm}\",\n",
    "            \"--n_events\",    f\"{self.n_events}\",\n",
    "            \"--out_dir\",     \"{OUT_DIR_PLACEHOLDER}\",\n",
    "        ]\n",
    "\n",
    "    def as_vector(self) -> np.ndarray:\n",
    "        return np.array([\n",
    "            self.a_mm, self.r_neck_mm, self.r_max_mm,\n",
    "            self.Rout_mm, self.zMin_mm, self.zMax_mm,\n",
    "            self.I_A, self.spacing_mm\n",
    "        ], dtype=float)\n",
    "\n",
    "    def validate(self) -> bool:\n",
    "        \"\"\"Validate that parameters create valid geometry.\"\"\"\n",
    "        return (\n",
    "            self.a_mm > 0 and\n",
    "            self.r_neck_mm > 0 and\n",
    "            self.r_max_mm > self.r_neck_mm and\n",
    "            self.Rout_mm > self.r_max_mm and\n",
    "            self.zMax_mm > self.zMin_mm and\n",
    "            self.zMax_mm > 0 and\n",
    "            self.I_A != 0 and\n",
    "            self.spacing_mm > 0\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def names() -> List[str]:\n",
    "        return [\"a_mm\",\"r_neck_mm\",\"r_max_mm\",\"Rout_mm\",\"zMin_mm\",\"zMax_mm\",\"I_A\",\"spacing_mm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc67f2",
   "metadata": {},
   "source": [
    "## Beam statistics (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0265e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_stats_gpu(x_mm, y_mm, px, py, pz, E_MeV,\n",
    "                   E_min: Optional[float]=None, E_max: Optional[float]=None,\n",
    "                   N_in: Optional[int]=None, a_mm: Optional[float]=None,\n",
    "                   mass_MeV: float=PI_PLUS_MASS_MEV) -> Dict[str,float]:\n",
    "    \"\"\"GPU-accelerated beam statistics calculation.\"\"\"\n",
    "\n",
    "    # Convert to tensors and move to GPU\n",
    "    x = torch.tensor(x_mm, dtype=torch.float32, device=DEVICE)\n",
    "    y = torch.tensor(y_mm, dtype=torch.float32, device=DEVICE)\n",
    "    px = torch.tensor(px, dtype=torch.float32, device=DEVICE)\n",
    "    py = torch.tensor(py, dtype=torch.float32, device=DEVICE)\n",
    "    pz = torch.tensor(pz, dtype=torch.float32, device=DEVICE)\n",
    "    E = torch.tensor(E_MeV, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    # Create mask for valid particles\n",
    "    mask = torch.isfinite(pz) & (pz != 0.0)\n",
    "    if E_min is not None: mask &= (E >= E_min)\n",
    "    if E_max is not None: mask &= (E <= E_max)\n",
    "\n",
    "    if not torch.any(mask):\n",
    "        return {\"N_out\": 0, \"eta_trans\": 0.0}\n",
    "\n",
    "    # Apply mask\n",
    "    x, y, px, py, pz, E = x[mask], y[mask], px[mask], py[mask], pz[mask], E[mask]\n",
    "    xp, yp = px/pz, py/pz\n",
    "\n",
    "    # Calculate covariances using GPU\n",
    "    def cov2_gpu(a, b):\n",
    "        am, bm = a.mean(), b.mean()\n",
    "        return (a*b).mean() - am*bm\n",
    "\n",
    "    Sxx, Sxpx, Sxpxp = cov2_gpu(x,x), cov2_gpu(x,xp), cov2_gpu(xp,xp)\n",
    "    Syy, Sypy, Syyp = cov2_gpu(y,y), cov2_gpu(y,yp), cov2_gpu(yp,yp)\n",
    "\n",
    "    dxxp = Sxx*Sxpxp - Sxpx**2\n",
    "    dyyp = Syy*Syyp  - Sypy**2\n",
    "\n",
    "    eps_x = torch.sqrt(torch.clamp(dxxp, min=0.0))\n",
    "    eps_y = torch.sqrt(torch.clamp(dyyp, min=0.0))\n",
    "\n",
    "    beta_x  = torch.where(eps_x > 0, Sxx/eps_x, torch.tensor(0.0, device=DEVICE))\n",
    "    alpha_x = torch.where(eps_x > 0, -Sxpx/eps_x, torch.tensor(0.0, device=DEVICE))\n",
    "    beta_y  = torch.where(eps_y > 0, Syy/eps_y, torch.tensor(0.0, device=DEVICE))\n",
    "    alpha_y = torch.where(eps_y > 0, -Sypy/eps_y, torch.tensor(0.0, device=DEVICE))\n",
    "\n",
    "    sig_x, sig_xp = torch.sqrt(torch.clamp(Sxx, min=0.0)), torch.sqrt(torch.clamp(Sxpxp, min=0.0))\n",
    "    sig_y, sig_yp = torch.sqrt(torch.clamp(Syy, min=0.0)), torch.sqrt(torch.clamp(Syyp, min=0.0))\n",
    "    sig_theta_rms = torch.sqrt(0.5*(sig_xp**2 + sig_yp**2))\n",
    "    eps4D = eps_x * eps_y\n",
    "\n",
    "    N_out = x.size(0)\n",
    "    eta_trans = (N_out/float(N_in)) if (N_in is not None and N_in>0) else float('nan')\n",
    "\n",
    "    Emean = E.mean()\n",
    "    gamma = Emean / mass_MeV\n",
    "    beta_rel = torch.sqrt(torch.clamp(1 - 1/(gamma**2), min=0.0))\n",
    "    epsn_x, epsn_y = beta_rel*gamma*eps_x, beta_rel*gamma*eps_y\n",
    "\n",
    "    eps_acc_x = torch.where(beta_x > 0, (a_mm**2 / beta_x), torch.tensor(float('nan'), device=DEVICE)) if a_mm is not None else torch.tensor(float('nan'), device=DEVICE)\n",
    "    eps_acc_y = torch.where(beta_y > 0, (a_mm**2 / beta_y), torch.tensor(float('nan'), device=DEVICE)) if a_mm is not None else torch.tensor(float('nan'), device=DEVICE)\n",
    "\n",
    "    # Convert back to CPU for return\n",
    "    return dict(\n",
    "        N_out=int(N_out), eta_trans=float(eta_trans),\n",
    "        eps_x=float(eps_x), eps_y=float(eps_y), epsn_x=float(epsn_x), epsn_y=float(epsn_y),\n",
    "        beta_x=float(beta_x), alpha_x=float(alpha_x), beta_y=float(beta_y), alpha_y=float(alpha_y),\n",
    "        sigma_x_mm=float(sig_x), sigma_y_mm=float(sig_y), sigma_xp=float(sig_xp), sigma_yp=float(sig_yp),\n",
    "        sigma_theta_rms=float(sig_theta_rms), eps_4D=float(eps4D),\n",
    "        eps_acc_x=float(eps_acc_x), eps_acc_y=float(eps_acc_y),\n",
    "        gamma_rel=float(gamma), beta_rel=float(beta_rel)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3d263",
   "metadata": {},
   "source": [
    "## Merge per-thread CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_thread_csvs(out_dir: str, pattern=\"6D_vector_run0_t*.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Merge CSV files from multiple threads.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(out_dir, pattern)))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No per-thread CSVs in {out_dir} matching {pattern}\")\n",
    "    return pd.concat([pd.read_csv(f) for f in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb441c9",
   "metadata": {},
   "source": [
    "## Run a single Geant4 simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ebf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_geant4_simple(params: HornParams) -> Tuple[pd.DataFrame, str]:\n",
    "    \"\"\"Run a single Geant4 simulation with minimal logging.\"\"\"\n",
    "    # Create unique run directory\n",
    "    run_id = f\"run_{int(time.time() * 1000)}_{hash(str(params)) % 10000}\"\n",
    "    run_dir = os.path.join(RUNS_ROOT, run_id)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # Build CLI\n",
    "    cli = params.as_cli()\n",
    "    for i, tok in enumerate(cli):\n",
    "        if tok == \"{OUT_DIR_PLACEHOLDER}\":\n",
    "            cli[i] = run_dir\n",
    "\n",
    "    exe = GEANT4_EXE\n",
    "    cmd = [exe] + cli\n",
    "\n",
    "    # Environment\n",
    "    env = os.environ.copy()\n",
    "    env.update(EXTRA_ENV)\n",
    "\n",
    "    # Run Geant4\n",
    "    try:\n",
    "        res = subprocess.run(\n",
    "            cmd, \n",
    "            cwd=run_dir, \n",
    "            text=True, \n",
    "            capture_output=True, \n",
    "            env=env, \n",
    "            timeout=1200,  # 20 minutes\n",
    "        )\n",
    "\n",
    "        if res.returncode != 0:\n",
    "            raise RuntimeError(f\"Geant4 failed with exit code {res.returncode}\")\n",
    "\n",
    "        # Process results\n",
    "        df = merge_thread_csvs(run_dir)\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No particle tracks found\")\n",
    "\n",
    "        return df, run_dir\n",
    "\n",
    "    except Exception as e:\n",
    "        # Clean up on failure\n",
    "        if os.path.exists(run_dir):\n",
    "            shutil.rmtree(run_dir)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92632d2",
   "metadata": {},
   "source": [
    "## Physics-informed geometry penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2738a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometry_penalty(hp: HornParams) -> float:\n",
    "    \"\"\"Physics-informed penalties to discourage non-physical designs.\"\"\"\n",
    "    p = 0.0\n",
    "    margin = 2.0\n",
    "    min_len = 200.0\n",
    "\n",
    "    # Basic geometry constraints\n",
    "    if not (hp.r_max_mm > hp.r_neck_mm + margin): \n",
    "        p += (hp.r_neck_mm + margin - hp.r_max_mm)**2\n",
    "    if not (hp.Rout_mm > hp.r_max_mm + margin):  \n",
    "        p += (hp.r_max_mm + margin - hp.Rout_mm)**2\n",
    "    if not (hp.zMax_mm > hp.zMin_mm + min_len):  \n",
    "        p += (hp.zMin_mm + min_len - hp.zMax_mm)**2\n",
    "    if not (hp.spacing_mm > 0):                   \n",
    "        p += (1.0 - hp.spacing_mm)**2\n",
    "\n",
    "    # Parabola consistency\n",
    "    w_cons = 0.1\n",
    "    lhs = hp.r_max_mm**2\n",
    "    rhs = hp.r_neck_mm**2 + (hp.zMax_mm - hp.zMin_mm)/hp.a_mm\n",
    "    p += w_cons * (lhs - rhs)**2\n",
    "\n",
    "    # Current density constraint\n",
    "    conductor_area = np.pi * (hp.Rout_mm**2 - hp.r_max_mm**2)\n",
    "    current_density = hp.I_A / (conductor_area * 1e-6)\n",
    "    max_current_density = 1e7\n",
    "    if current_density > max_current_density:\n",
    "        p += (current_density - max_current_density)**2 * 1e-12\n",
    "\n",
    "    # Magnetic field constraint\n",
    "    mu_0 = 4e-7 * np.pi\n",
    "    peak_field = mu_0 * hp.I_A / (2 * np.pi * hp.r_neck_mm * 1e-3)\n",
    "    max_field = 10.0\n",
    "    if peak_field > max_field:\n",
    "        p += (peak_field - max_field)**2 * 1e-6\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5837582",
   "metadata": {},
   "source": [
    "## Score from track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_from_tracks(df: pd.DataFrame, hp: HornParams,\n",
    "                      N_in: Optional[int]=None,\n",
    "                      energy_window: Optional[Tuple[float,float]]=DEFAULT_ENERGY_WINDOW) -> Dict[str,float]:\n",
    "    \"\"\"Score tracks using GPU-accelerated calculations.\"\"\"\n",
    "    if energy_window:\n",
    "        lo, hi = energy_window\n",
    "        df = df[(df[\"E[GeV]\"] >= lo/1000) & (df[\"E[GeV]\"] <= hi/1000)].copy()\n",
    "\n",
    "    # Use GPU-accelerated beam statistics\n",
    "    stats = beam_stats_gpu(\n",
    "        x_mm=df[\"x[mm]\"].values, y_mm=df[\"y[mm]\"].values,\n",
    "        px=df[\"px[MeV/c]\"].values, py=df[\"py[MeV/c]\"].values, pz=df[\"pz[MeV/c]\"].values,\n",
    "        E_MeV=df[\"E[GeV]\"].values * 1000,  # Convert GeV to MeV\n",
    "        E_min=None, E_max=None, N_in=N_in, a_mm=hp.a_mm, mass_MeV=PI_PLUS_MASS_MEV\n",
    "    )\n",
    "\n",
    "    # Calculate objective function\n",
    "    eta = stats.get(\"eta_trans\", 0.0)\n",
    "    if np.isnan(eta):\n",
    "        eta = len(df) / max(len(df), 1)\n",
    "\n",
    "    epsn_mean = 0.5*(stats[\"epsn_x\"] + stats[\"epsn_y\"])\n",
    "    div = stats[\"sigma_theta_rms\"]\n",
    "\n",
    "    # Acceptance reward\n",
    "    if np.isfinite(stats[\"eps_acc_x\"]) and np.isfinite(stats[\"eps_acc_y\"]):\n",
    "        r_acc = min(stats[\"eps_acc_x\"]/max(stats[\"eps_x\"],1e-12),\n",
    "                    stats[\"eps_acc_y\"]/max(stats[\"eps_y\"],1e-12))\n",
    "        acc_reward = min(r_acc, 1.0)\n",
    "    else:\n",
    "        acc_reward = 0.5\n",
    "\n",
    "    # Physics-informed objective function - focus on emittance and particle count\n",
    "    # Primary: maximize particle count (transmission efficiency)\n",
    "    # Secondary: minimize emittance (beam quality)\n",
    "    w_trans, w_emit = 0.7, 0.3\n",
    "\n",
    "    # Particle count (transmission efficiency)\n",
    "    particle_count = len(df)\n",
    "\n",
    "    # Emittance (lower is better)\n",
    "    emittance = epsn_mean\n",
    "\n",
    "    objective = (w_trans * eta - w_emit * emittance)\n",
    "\n",
    "    focusing_strength = hp.I_A / (hp.r_neck_mm * hp.a_mm)\n",
    "    compression_ratio = hp.r_max_mm / hp.r_neck_mm if hp.r_neck_mm > 0 else 1.0\n",
    "\n",
    "    stats.update(dict(\n",
    "        eta_trans=eta, epsn_mean=epsn_mean,\n",
    "        particle_count=particle_count, emittance=emittance,\n",
    "        objective=objective, transmission=eta,\n",
    "        focusing_strength=focusing_strength, compression_ratio=compression_ratio\n",
    "    ))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159184b",
   "metadata": {},
   "source": [
    "## Train XGBoost (GPU‑optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_gpu(X: np.ndarray, y: np.ndarray, early_stopping_rounds: int = 50):\n",
    "    \"\"\"Train XGBoost with GPU acceleration.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "    Xtr, Xva, ytr, yva = train_test_split(Xs, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "    # XGBoost with GPU support\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        max_depth=8,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        tree_method='gpu_hist' if GPU_COUNT > 0 else 'hist',  # GPU acceleration\n",
    "        gpu_id=0 if GPU_COUNT > 0 else None,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        Xtr, ytr, \n",
    "        eval_set=[(Xva, yva)], \n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2545325",
   "metadata": {},
   "source": [
    "## Append results to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dataset(hp: HornParams, stats: Dict[str,float], path: str = DATASET):\n",
    "    \"\"\"Append results to dataset.\"\"\"\n",
    "    row = {**{k:v for k,v in asdict(hp).items()}, **stats}\n",
    "    df_row = pd.DataFrame([row])\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = pd.concat([df, df_row], ignore_index=True)\n",
    "    else:\n",
    "        df = df_row\n",
    "    df.to_csv(path, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a927725",
   "metadata": {},
   "source": [
    "## Sample uniform candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_uniform(bounds: Dict[str, tuple | float], n: int) -> List[HornParams]:\n",
    "    \"\"\"Sample uniform parameters with validation.\"\"\"\n",
    "    names = HornParams.names()\n",
    "    out = []\n",
    "    max_attempts = n * 10  # Allow up to 10x attempts to get valid parameters\n",
    "    attempts = 0\n",
    "\n",
    "    while len(out) < n and attempts < max_attempts:\n",
    "        draw = {}\n",
    "        for nm in names:\n",
    "            if isinstance(bounds[nm], (list, tuple)):\n",
    "                lo, hi = bounds[nm]\n",
    "                val = np.random.uniform(lo, hi)\n",
    "            else:\n",
    "                val = bounds[nm]\n",
    "            draw[nm] = float(val)\n",
    "\n",
    "        hp = HornParams(**draw)\n",
    "        if hp.validate():\n",
    "            out.append(hp)\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    # If we still don't have enough, use default valid parameters\n",
    "    while len(out) < n:\n",
    "        hp = HornParams(\n",
    "            a_mm=0.01, r_neck_mm=300.0, r_max_mm=500.0, Rout_mm=800.0,\n",
    "            zMin_mm=0.0, zMax_mm=2000.0, I_A=75000.0, spacing_mm=1500.0\n",
    "        )\n",
    "        out.append(hp)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc1f71",
   "metadata": {},
   "source": [
    "## Propose from XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_from_xgb(model, scaler, bounds: Dict[str, tuple | float], k: int = 20) -> List[HornParams]:\n",
    "    \"\"\"Generate candidates using XGBoost.\"\"\"\n",
    "    names = HornParams.names()\n",
    "    N = 2000\n",
    "    cand = np.zeros((N, len(names)), dtype=float)\n",
    "    for j, nm in enumerate(names):\n",
    "        if isinstance(bounds[nm], (list, tuple)):\n",
    "            lo, hi = bounds[nm]\n",
    "            cand[:, j] = np.random.uniform(lo, hi, size=N)\n",
    "        else:\n",
    "            cand[:, j] = bounds[nm]\n",
    "\n",
    "    pred = model.predict(scaler.transform(cand))\n",
    "    idx = np.argsort(pred)[::-1][:k]\n",
    "\n",
    "    hps = []\n",
    "    for i in idx:\n",
    "        v = cand[i]\n",
    "        hp = HornParams(\n",
    "            a_mm=float(v[0]), r_neck_mm=float(v[1]), r_max_mm=float(v[2]),\n",
    "            Rout_mm=float(v[3]), zMin_mm=float(v[4]), zMax_mm=float(v[5]),\n",
    "            I_A=float(v[6]), spacing_mm=float(v[7])\n",
    "        )\n",
    "        # Only add valid parameters\n",
    "        if hp.validate():\n",
    "            hps.append(hp)\n",
    "\n",
    "    # If we don't have enough valid parameters, fill with random valid ones\n",
    "    while len(hps) < k:\n",
    "        hp = sample_uniform(bounds, 1)[0]\n",
    "        hps.append(hp)\n",
    "\n",
    "    return hps[:k]  # Return exactly k parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ec7a0",
   "metadata": {},
   "source": [
    "## Main optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cluster(bounds: Dict[str,Tuple[float,float]], \n",
    "                   n_seed: int=6, n_rounds: int=4, \n",
    "                   k_candidates: int=3, parallel_eval: bool=True):\n",
    "    \"\"\"GPU-accelerated optimization with minimal logging.\"\"\"\n",
    "\n",
    "    print(f\"🚀 Starting horn optimization with GPU acceleration\")\n",
    "    print(f\"   Device: {DEVICE}, GPUs: {GPU_COUNT}\")\n",
    "\n",
    "    # Initialize\n",
    "    X, y = [], []\n",
    "\n",
    "    # Load existing dataset\n",
    "    if os.path.exists(DATASET):\n",
    "        try:\n",
    "            ds = pd.read_csv(DATASET)\n",
    "            if set(HornParams.names()).issubset(ds.columns) and \"objective\" in ds.columns:\n",
    "                X = ds[HornParams.names()].values.tolist()\n",
    "                y = ds[\"objective\"].values.tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "    # Seed phase - ensure we get successful samples\n",
    "    print(f\"🌱 EPOCH 0: Seed phase ({n_seed} samples)\")\n",
    "    X, y = [], []\n",
    "    max_retries = n_seed * 3  # Allow up to 3x retries\n",
    "    retry_count = 0\n",
    "\n",
    "    while len(X) < n_seed and retry_count < max_retries:\n",
    "        try:\n",
    "            hp = sample_uniform(bounds, 1)[0]\n",
    "            df, run_dir = run_geant4_simple(hp)\n",
    "            stats = score_from_tracks(df, hp, N_in=hp.n_events)\n",
    "            append_to_dataset(hp, stats)\n",
    "            X.append(hp.as_vector().tolist())\n",
    "            y.append(stats[\"objective\"])\n",
    "\n",
    "            # Clean up run directory\n",
    "            if os.path.exists(run_dir):\n",
    "                shutil.rmtree(run_dir)\n",
    "\n",
    "            print(f\"   ✓ Sample {len(X)}/{n_seed} successful\")\n",
    "\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"   ✗ Sample failed (retry {retry_count}/{max_retries}): {e}\")\n",
    "\n",
    "            # Clean up failed run directory\n",
    "            try:\n",
    "                if 'run_dir' in locals() and os.path.exists(run_dir):\n",
    "                    shutil.rmtree(run_dir)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Check if we have any successful samples\n",
    "    if len(X) == 0:\n",
    "        raise RuntimeError(\"No successful samples from seed phase - check Geant4 executable and parameters\")\n",
    "\n",
    "    # Train initial model\n",
    "    if len(X) < 2:\n",
    "        print(f\"Warning: Only {len(X)} successful samples, using random sampling for first round\")\n",
    "        xgb_model, scaler = None, None\n",
    "    else:\n",
    "        try:\n",
    "            X_arr, y_arr = np.array(X, float), np.array(y, float)\n",
    "            xgb_model, scaler = train_xgb_gpu(X_arr, y_arr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error training initial model: {e}\")\n",
    "            xgb_model, scaler = None, None\n",
    "\n",
    "    # Optimization rounds\n",
    "    for r in range(1, n_rounds + 1):\n",
    "        print(f\"🔄 EPOCH {r}: Starting optimization round\")\n",
    "\n",
    "        # Generate candidates\n",
    "        try:\n",
    "            if xgb_model is not None and scaler is not None:\n",
    "                cands = propose_from_xgb(xgb_model, scaler, bounds, k=k_candidates)\n",
    "            else:\n",
    "                cands = sample_uniform(bounds, k_candidates)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating candidates: {e}\")\n",
    "            cands = sample_uniform(bounds, k_candidates)\n",
    "\n",
    "        # Evaluate candidates\n",
    "        round_scores = []\n",
    "        for hp in cands:\n",
    "            try:\n",
    "                df, run_dir = run_geant4_simple(hp)\n",
    "                stats = score_from_tracks(df, hp, N_in=hp.n_events)\n",
    "                append_to_dataset(hp, stats)\n",
    "                X.append(hp.as_vector().tolist())\n",
    "                y.append(stats[\"objective\"])\n",
    "                round_scores.append(stats[\"objective\"])\n",
    "\n",
    "                # Clean up run directory\n",
    "                if os.path.exists(run_dir):\n",
    "                    shutil.rmtree(run_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating candidate: {e}\")\n",
    "\n",
    "        # Retrain model\n",
    "        if round_scores and len(X) >= 2:\n",
    "            try:\n",
    "                X_arr, y_arr = np.array(X, float), np.array(y, float)\n",
    "                xgb_model, scaler = train_xgb_gpu(X_arr, y_arr)\n",
    "            except Exception as e:\n",
    "                print(f\"Error retraining model: {e}\")\n",
    "                xgb_model, scaler = None, None\n",
    "\n",
    "            # Print epoch completion with best parameters\n",
    "            best_score = max(round_scores)\n",
    "            ds = pd.read_csv(DATASET)\n",
    "            best = ds.loc[ds[\"objective\"].idxmax()]\n",
    "            print(f\"✅ EPOCH {r} COMPLETE: Best objective = {best['objective']:.4f}\")\n",
    "            print(f\"   Particle count: {best.get('particle_count', 'N/A')}, Emittance: {best.get('emittance', 'N/A'):.4f}\")\n",
    "            print(f\"   Best parameters: a={best['a_mm']:.4f}, r_neck={best['r_neck_mm']:.1f}, r_max={best['r_max_mm']:.1f}, Rout={best['Rout_mm']:.1f}, zMax={best['zMax_mm']:.1f}, I={best['I_A']:.0f}, spacing={best['spacing_mm']:.1f}\")\n",
    "\n",
    "    # Final results\n",
    "    try:\n",
    "        ds = pd.read_csv(DATASET)\n",
    "        best = ds.loc[ds[\"objective\"].idxmax()]\n",
    "        print(f\"\\n🎯 OPTIMIZATION COMPLETE\")\n",
    "        print(f\"   Total evaluations: {len(ds)}\")\n",
    "        print(f\"   Best objective: {best['objective']:.4f}\")\n",
    "        print(f\"   Best particle count: {best.get('particle_count', 'N/A')}\")\n",
    "        print(f\"   Best emittance: {best.get('emittance', 'N/A'):.4f}\")\n",
    "        print(f\"   Best parameters:\")\n",
    "        for param in HornParams.names():\n",
    "            print(f\"     {param}: {best[param]:.4f}\")\n",
    "\n",
    "        # Save results\n",
    "        results_file = os.path.join(RESULTS_DIR, \"best_design.json\")\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(best.to_dict(), f, indent=2)\n",
    "        print(f\"   Results saved to: {results_file}\")\n",
    "\n",
    "        return best\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading final results: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d7880",
   "metadata": {},
   "source": [
    "## Default bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a48e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default bounds\n",
    "DEFAULT_BOUNDS = {\n",
    "    \"a_mm\":       (0.005, 0.02),\n",
    "    \"r_neck_mm\":  (200.0, 400.0),\n",
    "    \"r_max_mm\":   (400.0, 700.0),\n",
    "    \"Rout_mm\":    (700.0, 1200.0),\n",
    "    \"zMin_mm\":    (0.0),\n",
    "    \"zMax_mm\":    (1500.0, 3000.0),\n",
    "    \"I_A\":        (30000.0, 150000.0),\n",
    "    \"spacing_mm\": (1000.0, 4000.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3758d",
   "metadata": {},
   "source": [
    "## Entrypoint (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed62796",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"🔧 Starting GPU-optimized horn optimization for compute cluster\")\n",
    "    print(\"   - CUDA-accelerated data processing\")\n",
    "    print(\"   - Multi-GPU support\")\n",
    "    print(\"   - Parallel Geant4 execution\")\n",
    "    print(\"   - Cluster-optimized resource management\")\n",
    "\n",
    "    try:\n",
    "        result = optimize_cluster(\n",
    "            DEFAULT_BOUNDS, \n",
    "            n_seed=6, \n",
    "            n_rounds=4, \n",
    "            k_candidates=3,\n",
    "            parallel_eval=True\n",
    "        )\n",
    "\n",
    "        if result is not None:\n",
    "            print(\"✅ Optimization completed successfully!\")\n",
    "        else:\n",
    "            print(\"❌ Optimization failed - check error messages above\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 Optimization interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Optimization failed with error: {e}\")\n",
    "        print(\"   Check the error messages above for details\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
